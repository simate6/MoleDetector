{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Object detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from keras.models import load_model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code slices the image under diagnoses into smaller parts with different shifts in both x and y directions and with different window sizes. The input for the classificator CNN is a 32 x 32 3-channel image. The idea was to start with a 32x32 window and double the size after a segmentation is completed. For one segmentation cycle the window is shifted by one-third of the window size in each iteration in x and y direction separately. The code is also responsible for creating an instruction matrix, which links the input image to the corresponding image position and bounding box size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def test(img_name, save=False):\n",
    "    # load model\n",
    "    model = load_model('Weights/cnn_weights.hdf5')\n",
    "    modelMLP = load_model('Weights/mlp_weights.hdf5')\n",
    "\n",
    "    shift = np.array([10,20,40], dtype=np.uint8) #window shifted by number of pixels\n",
    "    size = np.array([32], dtype=np.uint8) #window sizes in pixels\n",
    "\n",
    "    uniform_size = 32 #input size of the classificator CNN\n",
    "    i = 0\n",
    "\n",
    "    for i_shift, i_size in zip(shift, size): #linking the two jointly changed parameters\n",
    "        for step_y in range(0,3): #shifting the slicing grid in y direction\n",
    "            for step_x in range(0,3): #shifting the slicing grid in x direction\n",
    "                diagimg = np.asarray(PIL.Image.open(img_name)) #reading the currently diagnosed input image\n",
    "                diagimg = diagimg[i_shift*step_y:, i_shift*step_x:]  #shifting the image according to the corresponding parameters\n",
    "                grid = diagimg[0:(diagimg.shape[0]//i_size)*i_size, 0:(diagimg.shape[1]//i_size)*i_size] #cropping the image to fit even windows\n",
    "                grid_sliced = np.asarray(np.split(grid, grid.shape[0]//i_size, axis = 0)) #slicing the image in y direction\n",
    "                grid_sliced = np.asarray(np.split(grid_sliced, grid_sliced.shape[2]//i_size, axis = 2)) #slicing the image in x direction\n",
    "                grid_sliced = np.reshape(grid_sliced, (grid_sliced.shape[0]*grid_sliced.shape[1], i_size, i_size, 3)) #reshaping the image into a column array each row containing a sliced window\n",
    "\n",
    "                vector_x = np.arange(i_shift*step_x, grid.shape[1], i_size) #getting the window positions in x direction\n",
    "                vector_y = np.arange(i_shift*step_y, grid.shape[0], i_size) #getting the window positions in y direction\n",
    "                matrix = np.asarray(np.meshgrid(vector_x, vector_y, sparse=False, indexing='ij')) #creating the window position matrix\n",
    "                info_img = np.transpose(np.reshape(matrix, (2,matrix.shape[1]*matrix.shape[2]))) #reshaping the window position matrix into a column array, each row containing the position of the correspondig sliced window\n",
    "                info_img = np.concatenate((info_img, np.multiply(i_size,np.ones((info_img.shape[0],1)))), axis=1) #adding the size of the windows to the column array as plus information\n",
    "\n",
    "                if i_size > uniform_size:\n",
    "                    out_shape = grid_sliced.shape[0], uniform_size, grid_sliced.shape[1]//uniform_size, uniform_size, grid_sliced.shape[2]//uniform_size, 3 #defining the expected image size for the CNN\n",
    "                    grid_sliced = grid_sliced.reshape(out_shape).mean(2).mean(3) #resizing the images according to the expected shape for the CNN\n",
    "                if i==0:\n",
    "                    input_sequence = grid_sliced\n",
    "                    info = info_img\n",
    "                    i += 1\n",
    "                else:\n",
    "                    input_sequence = np.append(input_sequence, grid_sliced, axis = 0) #extending the input_sequence with the current new inputs\n",
    "                    info = np.vstack((info,info_img)) #extending the information array with the current new information\n",
    "                    i += 1\n",
    "\n",
    "    info[:, 0], info[:, 1] = info[:, 1], info[:, 0].copy() #changing the order of the x and y positions of the windows\n",
    "\n",
    "    input_sequence_scaled = input_sequence/255 #normalizing the input images\n",
    "\n",
    "    # predict & draw\n",
    "    preds = model.predict(input_sequence_scaled)\n",
    "    diagimg = np.asarray(PIL.Image.open(img_name))\n",
    "\n",
    "    #figure = plt.figure()\n",
    "    fig, ax = plt.subplots(1,figsize=(25,15))\n",
    "    ax.imshow(diagimg)\n",
    "    ax.set_axis_off()\n",
    "    for i in range(0,preds.shape[0]):\n",
    "        if preds[i,1] > 0.2 and preds[i,0]<0.1:\n",
    "            #rect = patches.Rectangle((info[i,1],info[i,0]),info[i,2],info[i,2],linewidth=2,edgecolor='r',facecolor='none')\n",
    "            #ax.add_patch(rect)\n",
    "            roi = diagimg[info[i,0].astype(int):info[i,0].astype(int)+info[i,2].astype(int), info[i,1].astype(int):info[i,1].astype(int)+info[i,2].astype(int)]\n",
    "            roigray = cv2.cvtColor(roi, cv2.COLOR_RGB2GRAY)\n",
    "            #plt.imshow(roigray,cmap='gray')\n",
    "            #mlp_input = np.zeros(shape=(1,32,32))\n",
    "            #mlp_input[0] = roigray\n",
    "            roigrayinput = np.expand_dims(roigray,0)\n",
    "            roigrayinput = roigrayinput.reshape(roigrayinput.shape[0], -1)\n",
    "            stackeddecision = modelMLP.predict(roigrayinput)\n",
    "            if stackeddecision[0,1] > 0.9 and stackeddecision[0,0] < 0.1:\n",
    "                rect = patches.Rectangle((info[i,1],info[i,0]),info[i,2],info[i,2],linewidth=2,edgecolor='r',facecolor='none')\n",
    "                ax.add_patch(rect)\n",
    "                \n",
    "    if save:\n",
    "        plt.savefig(img_name[:-4] + '_md' + img_name[-4:])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test('Test/3.jpg', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_tensorflow-gpu",
   "language": "python",
   "name": "env_tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
